{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "df08f20a",
   "metadata": {},
   "source": [
    "# Machine Learning Intern at Infopillar Solutions for November 2021 Batch\n",
    "\n",
    "# Author : Anand Bhausaheb Kharabe\n",
    "\n",
    "# Task 1 :Fake News Detection Project\n",
    "\n",
    "Project idea â€“ Fake news spreads like a wildfire and this is a big issue in this era. You can learn how to distinguish fake news from a real one. You can use supervised learning to implement a model like this.\n",
    "\n",
    "Dataset: https://bit.ly/3FxCSC4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa504197",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9a768ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f49d07c",
   "metadata": {},
   "source": [
    "# Reading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3808143",
   "metadata": {},
   "outputs": [],
   "source": [
    "t2 = pd.read_csv('news.csv')\n",
    "t2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81ceafa8",
   "metadata": {},
   "source": [
    "# EDA on the dataset variable t2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71288f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "t2.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f615f51c",
   "metadata": {},
   "outputs": [],
   "source": [
    "t2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83066383",
   "metadata": {},
   "outputs": [],
   "source": [
    "t2.drop(\"Unnamed: 0\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bffd72aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "t2.isnull().sum()  #Checking for NaN values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5add2c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "t2.duplicated().sum()  #Checking for Dublicate Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c832c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "t2.drop_duplicates(keep='first', inplace=True)  # Droping the dupicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db6d639a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(data=t2, x='label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f6aadbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from string import punctuation\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "ps = PorterStemmer()\n",
    "STOPWORDS = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b2700bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tranform_text(text):\n",
    "    text = text.lower()     # Converting to lower case\n",
    "\n",
    "    word_arr = nltk.word_tokenize(text)                                                     \n",
    "    correct = []\n",
    "\n",
    "    for word in word_arr:\n",
    "        if (word.isalnum()) and (word not in STOPWORDS) and (word not in punctuation):      \n",
    "            correct.append(ps.stem(word))                                                   \n",
    "\n",
    "    return \" \".join(correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caa51b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "t2['title'] = t2['title'].apply(tranform_text)\n",
    "t2['text'] = t2['text'].apply(tranform_text)\n",
    "t2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d41a13d6",
   "metadata": {},
   "source": [
    "# Using TF-IDF for Vectorizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4804dbd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf_title = TfidfVectorizer(max_features=3000)\n",
    "tfidf_text = TfidfVectorizer(max_features=20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb556bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "title = tfidf_title.fit_transform(t2['title']).toarray()\n",
    "text = tfidf_text.fit_transform(t2['text']).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "448a9c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Shape of Transformed Title :-> \",title.shape) \n",
    "print(\"Shape of Transformed Text :-> \",text.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f4e35d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_title = pd.DataFrame(title)\n",
    "df_text = pd.DataFrame(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b807973b",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = pd.concat([df_title, df_text], axis=1)\n",
    "t.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cef34280",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "target = le.fit_transform(dataset['label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "345894d1",
   "metadata": {},
   "source": [
    "# Train-Test-Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d4405c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(t, target, test_size=0.2, random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "985fd57b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6723e01a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d856d11",
   "metadata": {},
   "source": [
    "# Biulding Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "287b5e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "clf.fit(X_train,y_train)\n",
    "y_pred=clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdeda83d",
   "metadata": {},
   "outputs": [],
   "source": [
    "compare = pd.DataFrame({'Actual Values': y_test, 'Predicted Values': y_pred})  \n",
    "compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "105580ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "829eba8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix  \n",
    "print(confusion_matrix(y_test, y_pred))  \n",
    "print(classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
